{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries ðŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code ðŸ’»"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading saved matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matrices from previously generated files\n",
    "X_01 = np.load('matrices/X_01.npy')\n",
    "y_01 = np.load('matrices/y_01.npy')\n",
    "X_03 = np.load('matrices/X_03.npy')\n",
    "y_03 = np.load('matrices/y_03.npy')\n",
    "nX = np.load('matrices/nX.npy')\n",
    "ny = np.load('matrices/ny.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_03.shape, y_03.shape)\n",
    "print(X_01.shape, y_01.shape)\n",
    "print(nX.shape, ny.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the 0.1 the standard dataset\n",
    "X = X_01\n",
    "y = y_01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping with np.pad with zeros for a 21x21 CNN aproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the 0.1 the standard dataset\n",
    "X = X_01\n",
    "y = y_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "# We will use 80% of the data for training and 20% of the data for testing.\n",
    "# We will use the function train_test_split from sklearn.model_selection to split the data.\n",
    "# We will use the parameter stratify to split the data in a stratified way.\n",
    "# We will split the training data into training and validation sets.\n",
    "# We will use 80% of the training data for training and 20% of the training data for validation.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show target vector (1 = muon, 0 = antimuon)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_events = np.random.randint(0, X_train.shape[0], 1)\n",
    "\n",
    "for i in random_events:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 22))\n",
    "                                        \n",
    "        # Event\n",
    "        axs[0].imshow(X_train[i,:,:,0], cmap='Reds')\n",
    "        axs[0].set_title('Muon' if y_train[i] == 1 else 'Antimuon')\n",
    "        axs[1].imshow(X_train[i,:,:,1], cmap='Blues')\n",
    "        axs[1].set_title('Muon' if y_train[i] == 1 else 'Antimuon')\n",
    "\n",
    "        # Show tick labels on both sides\n",
    "        axs[0].tick_params('x', labelbottom=True, labeltop=True)\n",
    "        axs[0].tick_params('y', labelleft=True, labelright=True)\n",
    "        axs[0].set_xlabel('Side 1')\n",
    "\n",
    "        axs[1].tick_params('x', labelbottom=True, labeltop=True)\n",
    "        axs[1].tick_params('y', labelleft=True, labelright=True)\n",
    "        axs[1].set_xlabel('Side 2')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to bring the dimension from each matrix from 21,15,2 to 21,21,2.\n",
    "# We will use numpy.pad to pad the matrices with zeros.\n",
    "# We will pad the matrices with zeros in the third dimension (columns) and calculate the necessary padding for each matrix.\n",
    "\n",
    "X_train = np.pad(X_train, ((0,0),(0,0),(0, X_train.shape[1]-X_train.shape[2]), (0,0)), mode='constant')\n",
    "X_val = np.pad(X_val, ((0,0),(0,0),(0, X_val.shape[1]-X_val.shape[2]), (0,0)), mode='constant')\n",
    "X_test = np.pad(X_test, ((0,0),(0,0),(0, X_test.shape[1]-X_test.shape[2]), (0,0)), mode='constant')\n",
    "\n",
    "# Normalizing the data\n",
    "# We will use the function normalize from keras.utils to normalize the data.\n",
    "# We will normalize the data by dividing the data by the maximum value of the data.\n",
    "X_train = keras.utils.normalize(X_train, axis=1)\n",
    "X_val = keras.utils.normalize(X_val, axis=1)\n",
    "X_test = keras.utils.normalize(X_test, axis=1)\n",
    "\n",
    "# Reshape the y data to be a column one-hot encoded vector.\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_val = keras.utils.to_categorical(y_val, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show target vector ([0,1] = muon, [1,0] = antimuon)\n",
    "y_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in random_events:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 22))\n",
    "                                        \n",
    "        # Event\n",
    "        axs[0].imshow(X_train[i,:,:,0], cmap='Reds')\n",
    "        axs[0].set_title('Muon' if y_train[i][0] == 0 else 'Antimuon')\n",
    "        axs[1].imshow(X_train[i,:,:,1], cmap='Blues')\n",
    "        axs[1].set_title('Muon' if y_train[i][0] == 0 else 'Antimuon')\n",
    "\n",
    "        # Show tick labels on both sides\n",
    "        axs[0].tick_params('x', labelbottom=True, labeltop=True)\n",
    "        axs[0].tick_params('y', labelleft=True, labelright=True)\n",
    "        axs[0].set_xlabel('Side 1')\n",
    "\n",
    "        axs[1].tick_params('x', labelbottom=True, labeltop=True)\n",
    "        axs[1].tick_params('y', labelleft=True, labelright=True)\n",
    "        axs[1].set_xlabel('Side 2')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "# We will use a CNN to classify the events.\n",
    "# The input of the CNN will be a matrix with two channels (side 1 and side 2) with the energy deposited in each sparse coordinate.\n",
    "# The output of the CNN will be a vector with two elements (one for each class).\n",
    "# The CNN will have two convolutional layers, two max pooling layers and two dense layers.\n",
    "# The first convolutional layer will have 32 filters of size 3x3.\n",
    "# The second convolutional layer will have 64 filters of size 3x3.\n",
    "# The first max pooling layer will have a pool size of 2x2.\n",
    "# The second max pooling layer will have a pool size of 2x2.\n",
    "# The first dense layer will have 128 neurons.\n",
    "# The second dense layer will have 2 neurons.\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "# Create the CNN\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model and build F1 score metric\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[keras.metrics.Precision(), keras.metrics.Recall(), 'accuracy', f1_score])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Time the training\n",
    "start = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))\n",
    "end = time.time()\n",
    "print('Training time:', end - start)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss, accuracy and F1 score\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 7))\n",
    "axs[0].plot(history.history['loss'], label='Training loss')\n",
    "axs[0].plot(history.history['val_loss'], label='Validation loss')\n",
    "axs[0].set_title('Training and validation loss')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "axs[1].plot(history.history['accuracy'], label='Training accuracy')\n",
    "axs[1].plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "axs[1].set_title('Training and validation accuracy')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the precision, recall and F1 score\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 7))\n",
    "axs[0].plot(history.history['precision'], label='Training precision')\n",
    "axs[0].plot(history.history['val_precision'], label='Validation precision')\n",
    "axs[0].set_title('Training and validation precision')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Precision')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "axs[1].plot(history.history['recall'], label='Training recall')\n",
    "axs[1].plot(history.history['val_recall'], label='Validation recall')\n",
    "axs[1].set_title('Training and validation recall')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Recall')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "axs[2].plot(history.history['f1_score'], label='Training F1 score')\n",
    "axs[2].plot(history.history['val_f1_score'], label='Validation F1 score')\n",
    "axs[2].set_title('Training and validation F1 score')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('F1 score')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain test loss and accuracy, recall, precision and F1 score\n",
    "cnn_loss, cnn_precision, cnn_recall, cnn_accuracy, cnn_f1_score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)\n",
    "print(cnn_loss, cnn_precision, cnn_recall, cnn_accuracy, cnn_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "class_names = [\"Antimuons\", \"Muons\"]  \n",
    "plot_confusion_matrix(cm, classes=class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
